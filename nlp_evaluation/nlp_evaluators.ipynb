{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate with quantitative NLP evaluators\n",
        "\n",
        "## Objective\n",
        "This notebook demonstrates how to use NLP-based evaluators to assess the quality of generated text by comparing it to reference text. By the end of this tutorial, you'll be able to:\n",
        " - Understand different NLP evaluators such as `BleuScoreEvaluator`, `GleuScoreEvaluator`, `MeteorScoreEvaluator`, and `RougeScoreEvaluator`.\n",
        " - Evaluate dataset using these evaluators.\n",
        "\n",
        "## Time\n",
        "You should expect to spend about 10 minutes running this notebook.\n",
        "\n",
        "## Before you begin\n",
        "\n",
        "### Installation\n",
        "Install the following packages required to execute this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1733832648838
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: azure-ai-evaluation in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (1.1.0)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-ai-evaluation) (2.10.1)\n",
            "Requirement already satisfied: promptflow-devkit>=1.15.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-ai-evaluation) (1.16.2)\n",
            "Requirement already satisfied: nltk>=3.9.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-ai-evaluation) (3.9.1)\n",
            "Requirement already satisfied: azure-core>=1.30.2 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-ai-evaluation) (1.32.0)\n",
            "Requirement already satisfied: promptflow-core>=1.15.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-ai-evaluation) (1.16.2)\n",
            "Requirement already satisfied: azure-storage-blob>=12.10.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-ai-evaluation) (12.24.0)\n",
            "Requirement already satisfied: azure-identity>=1.16.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-ai-evaluation) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.21.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.17.0)\n",
            "Requirement already satisfied: cryptography>=2.5 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (44.0.0)\n",
            "Requirement already satisfied: msal>=1.30.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.31.1)\n",
            "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.2.0)\n",
            "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-storage-blob>=12.10.0->azure-ai-evaluation) (0.7.2)\n",
            "Requirement already satisfied: joblib in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (4.67.1)\n",
            "Requirement already satisfied: click in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.7)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (2.9.0.post0)\n",
            "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (0.18.6)\n",
            "Requirement already satisfied: filetype>=1.2.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (1.2.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (4.23.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (5.9.8)\n",
            "Requirement already satisfied: docstring_parser in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (0.16)\n",
            "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (0.115.6)\n",
            "Requirement already satisfied: promptflow-tracing==1.16.2 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (1.16.2)\n",
            "Requirement already satisfied: flask<4.0.0,>=2.2.3 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (3.1.0)\n",
            "Requirement already satisfied: openai in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation) (1.57.2)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation) (1.29.0)\n",
            "Requirement already satisfied: tiktoken>=0.4.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation) (0.8.0)\n",
            "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.7.3)\n",
            "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (7.0.7)\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.9.0)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.4.6)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.1.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (10.4.0)\n",
            "Requirement already satisfied: pywin32 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (308)\n",
            "Requirement already satisfied: httpx>=0.25.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.28.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.0.1)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.5.3 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (2.2.3)\n",
            "Requirement already satisfied: flask-cors<6.0.0,>=5.0.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (5.0.0)\n",
            "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.0.0b32)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.16.1)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (2.0.36)\n",
            "Requirement already satisfied: waitress<4.0.0,>=3.0.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.0.2)\n",
            "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.3.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.23.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.29.0)\n",
            "Requirement already satisfied: argcomplete>=3.2.3 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.5.2)\n",
            "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.1.43)\n",
            "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (24.3.1)\n",
            "Requirement already satisfied: msrest>=0.6.10 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.7.1)\n",
            "Requirement already satisfied: opentelemetry-api~=1.26 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.29.0)\n",
            "Requirement already satisfied: fixedint==0.1.6 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.1.6)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (1.17.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.15.0->azure-ai-evaluation) (2.10.3)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.15.0->azure-ai-evaluation) (0.41.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (3.1.4)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (1.9.0)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (6.4.5)\n",
            "Requirement already satisfied: aniso8601>=0.82 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (9.0.1)\n",
            "Requirement already satisfied: pytz in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (2024.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.15.0->azure-ai-evaluation) (4.0.11)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.0.7)\n",
            "Requirement already satisfied: idna in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (2024.8.30)\n",
            "Requirement already satisfied: anyio in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (4.7.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.15.0->azure-ai-evaluation) (2024.10.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.15.0->azure-ai-evaluation) (24.2.0)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.15.0->azure-ai-evaluation) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.15.0->azure-ai-evaluation) (0.22.3)\n",
            "Requirement already satisfied: pywin32-ctypes>=0.2.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.2.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.11.4 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (8.5.0)\n",
            "Requirement already satisfied: jaraco.classes in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.4.0)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.15.0->azure-ai-evaluation) (24.2)\n",
            "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity>=1.16.0->azure-ai-evaluation) (2.10.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.2.15)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.29.0)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from opentelemetry-proto==1.29.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (5.29.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit>=1.15.0->azure-ai-evaluation) (2024.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit>=1.15.0->azure-ai-evaluation) (2.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.2.3)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core>=1.15.0->azure-ai-evaluation) (0.2.12)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.1.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (2.22)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.15.0->azure-ai-evaluation) (5.0.1)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (3.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation) (2.0.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation) (0.50b0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0.0,>=0.109.0->promptflow-core>=1.15.0->azure-ai-evaluation) (2.27.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0.0,>=0.109.0->promptflow-core>=1.15.0->azure-ai-evaluation) (0.7.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from anyio->httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from anyio->httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.3.1)\n",
            "Requirement already satisfied: more-itertools in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (10.5.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from openai->promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation) (0.8.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from openai->promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation) (1.9.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sumohammed\\development\\aoai_model_evaluation_benchmarks\\aoai_eval\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install the packages\n",
        "%pip install azure-ai-evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1733832651097
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from pprint import pprint\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"../.credentials.env\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NLP Evaluators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BleuScoreEvaluator\n",
        "\n",
        "BLEU (Bilingual Evaluation Understudy) score is commonly used in natural language processing (NLP) and machine\n",
        "translation. It is widely used in text summarization and text generation use cases. It evaluates how closely the\n",
        "generated text matches the reference text. The BLEU score ranges from 0 to 1, with higher scores indicating\n",
        "better quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1733832657177
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.evaluation import BleuScoreEvaluator\n",
        "\n",
        "bleu = BleuScoreEvaluator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1733832659756
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bleu_score': 0.22961813530951883}\n"
          ]
        }
      ],
      "source": [
        "result = bleu(response=\"London is the capital of England.\", ground_truth=\"The capital of England is London.\")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GleuScoreEvaluator\n",
        "\n",
        "The GLEU (Google-BLEU) score evaluator measures the similarity between generated and reference texts by\n",
        "evaluating n-gram overlap, considering both precision and recall. This balanced evaluation, designed for\n",
        "sentence-level assessment, makes it ideal for detailed analysis of translation quality. GLEU is well-suited for\n",
        "use cases such as machine translation, text summarization, and text generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1733832671954
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.evaluation import GleuScoreEvaluator\n",
        "\n",
        "gleu = GleuScoreEvaluator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1733832673153
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'gleu_score': 0.4090909090909091}\n"
          ]
        }
      ],
      "source": [
        "result = gleu(response=\"London is the capital of England.\", ground_truth=\"The capital of England is London.\")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MeteorScoreEvaluator\n",
        "\n",
        "The METEOR (Metric for Evaluation of Translation with Explicit Ordering) score grader evaluates generated text by\n",
        "comparing it to reference texts, focusing on precision, recall, and content alignment. It addresses limitations of\n",
        "other metrics like BLEU by considering synonyms, stemming, and paraphrasing. METEOR score considers synonyms and\n",
        "word stems to more accurately capture meaning and language variations. In addition to machine translation and\n",
        "text summarization, paraphrase detection is an optimal use case for the METEOR score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1733832676855
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.evaluation import MeteorScoreEvaluator\n",
        "\n",
        "meteor = MeteorScoreEvaluator(alpha=0.9, beta=3.0, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1733832678928
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'meteor_score': 0.9067055393586005}\n"
          ]
        }
      ],
      "source": [
        "result = meteor(response=\"London is the capital of England.\", ground_truth=\"The capital of England is London.\")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RougeScoreEvaluator\n",
        "\n",
        "ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a set of metrics used to evaluate automatic\n",
        "summarization and machine translation. It measures the overlap between generated text and reference summaries.\n",
        "ROUGE focuses on recall-oriented measures to assess how well the generated text covers the reference text. Text\n",
        "summarization and document comparison are among optimal use cases for ROUGE, particularly in scenarios where text\n",
        "coherence and relevance are critical.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1733832695388
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.evaluation import RougeScoreEvaluator, RougeType\n",
        "\n",
        "rouge = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1733832715092
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge_precision': 1.0, 'rouge_recall': 1.0, 'rouge_f1_score': 1.0}\n"
          ]
        }
      ],
      "source": [
        "result = rouge(response=\"London is the capital of England.\", ground_truth=\"The capital of England is London.\")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate a Dataset using Math Evaluators\n",
        "\n",
        "The code below uses the Evaluate API with BLEU, GLEU, METEOR, and ROUGE evaluators to evaluate the results on a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1733832746096
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2024-12-20 10:14:21 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
            "[2024-12-20 10:14:21 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_bo0c_q9x_20241220_101420_607274, log path: C:\\Users\\sumohammed\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_bo0c_q9x_20241220_101420_607274\\logs.txt\n",
            "[2024-12-20 10:14:21 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
            "[2024-12-20 10:14:21 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
            "[2024-12-20 10:14:21 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
            "[2024-12-20 10:14:22 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_3hd7ofch_20241220_101420_611426, log path: C:\\Users\\sumohammed\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_3hd7ofch_20241220_101420_611426\\logs.txt\n",
            "[2024-12-20 10:14:22 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_564dpwb2_20241220_101420_615029, log path: C:\\Users\\sumohammed\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_564dpwb2_20241220_101420_615029\\logs.txt\n",
            "[2024-12-20 10:14:22 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_gtb5l99b_20241220_101420_616029, log path: C:\\Users\\sumohammed\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_gtb5l99b_20241220_101420_616029\\logs.txt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt flow service has started...\n",
            "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_bo0c_q9x_20241220_101420_607274\n",
            "Prompt flow service has started...\n",
            "Prompt flow service has started...\n",
            "Prompt flow service has started...\n",
            "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_3hd7ofch_20241220_101420_611426\n",
            "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_564dpwb2_20241220_101420_615029\n",
            "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_gtb5l99b_20241220_101420_616029\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Finished 3 / 3 lines.\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Average execution time for completed lines: 0.03 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
            "======= Run Summary =======\n",
            "\n",
            "Run name: \"azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_gtb5l99b_20241220_101420_616029\"\n",
            "Run status: \"Completed\"\n",
            "Start time: \"2024-12-20 10:14:20.599274+00:00\"\n",
            "Duration: \"0:00:03.046207\"\n",
            "Output path: \"C:\\Users\\sumohammed\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_gtb5l99b_20241220_101420_616029\"\n",
            "\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Finished 3 / 3 lines.\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Average execution time for completed lines: 0.18 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
            "======= Run Summary =======\n",
            "\n",
            "Run name: \"azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_564dpwb2_20241220_101420_615029\"\n",
            "Run status: \"Completed\"\n",
            "Start time: \"2024-12-20 10:14:20.599274+00:00\"\n",
            "Duration: \"0:00:03.038336\"\n",
            "Output path: \"C:\\Users\\sumohammed\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_564dpwb2_20241220_101420_615029\"\n",
            "\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Finished 3 / 3 lines.\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Average execution time for completed lines: 0.06 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
            "======= Run Summary =======\n",
            "\n",
            "Run name: \"azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_bo0c_q9x_20241220_101420_607274\"\n",
            "Run status: \"Completed\"\n",
            "Start time: \"2024-12-20 10:14:20.599274+00:00\"\n",
            "Duration: \"0:00:03.047221\"\n",
            "Output path: \"C:\\Users\\sumohammed\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_bo0c_q9x_20241220_101420_607274\"\n",
            "\n",
            "2024-12-20 10:14:25 +0000   61976 execution.bulk     INFO     Finished 3 / 3 lines.\n",
            "2024-12-20 10:14:25 +0000   61976 execution.bulk     INFO     Average execution time for completed lines: 1.2 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
            "2024-12-20 10:14:22 +0000   61976 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
            "2024-12-20 10:14:25 +0000   61976 execution.bulk     INFO     Finished 3 / 3 lines.\n",
            "2024-12-20 10:14:25 +0000   61976 execution.bulk     INFO     Average execution time for completed lines: 1.2 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
            "======= Run Summary =======\n",
            "\n",
            "Run name: \"azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_3hd7ofch_20241220_101420_611426\"\n",
            "Run status: \"Completed\"\n",
            "Start time: \"2024-12-20 10:14:20.599274+00:00\"\n",
            "Duration: \"0:00:05.356928\"\n",
            "Output path: \"C:\\Users\\sumohammed\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_3hd7ofch_20241220_101420_611426\"\n",
            "\n",
            "======= Combined Run Summary (Per Evaluator) =======\n",
            "\n",
            "{\n",
            "    \"bleu\": {\n",
            "        \"status\": \"Completed\",\n",
            "        \"duration\": \"0:00:03.047221\",\n",
            "        \"completed_lines\": 3,\n",
            "        \"failed_lines\": 0,\n",
            "        \"log_path\": \"C:\\\\Users\\\\sumohammed\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_bo0c_q9x_20241220_101420_607274\"\n",
            "    },\n",
            "    \"gleu\": {\n",
            "        \"status\": \"Completed\",\n",
            "        \"duration\": \"0:00:03.038336\",\n",
            "        \"completed_lines\": 3,\n",
            "        \"failed_lines\": 0,\n",
            "        \"log_path\": \"C:\\\\Users\\\\sumohammed\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_564dpwb2_20241220_101420_615029\"\n",
            "    },\n",
            "    \"meteor\": {\n",
            "        \"status\": \"Completed\",\n",
            "        \"duration\": \"0:00:05.356928\",\n",
            "        \"completed_lines\": 3,\n",
            "        \"failed_lines\": 0,\n",
            "        \"log_path\": \"C:\\\\Users\\\\sumohammed\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_3hd7ofch_20241220_101420_611426\"\n",
            "    },\n",
            "    \"rouge\": {\n",
            "        \"status\": \"Completed\",\n",
            "        \"duration\": \"0:00:03.046207\",\n",
            "        \"completed_lines\": 3,\n",
            "        \"failed_lines\": 0,\n",
            "        \"log_path\": \"C:\\\\Users\\\\sumohammed\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_gtb5l99b_20241220_101420_616029\"\n",
            "    }\n",
            "}\n",
            "\n",
            "====================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.evaluation import evaluate\n",
        "import random\n",
        "\n",
        "randomNum = random.randint(1111, 9999)\n",
        "result = evaluate(\n",
        "    data=\"nlp_data.jsonl\",\n",
        "    evaluation_name=\"NLP-demo-\" + str(randomNum),\n",
        "    evaluators={\n",
        "        \"bleu\": bleu,\n",
        "        \"gleu\": gleu,\n",
        "        \"meteor\": meteor,\n",
        "        \"rouge\": rouge,\n",
        "    },\n",
        "    # Optionally provide your AI Studio project information to track your evaluation results in your Azure AI Studio project\n",
        "    azure_ai_project = {\n",
        "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
        "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP\"),\n",
        "    \"project_name\": os.environ.get(\"AZURE_PROJECT_NAME\"),\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1733832746266
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metrics': {'bleu.bleu_score': 0.27619794053333335,\n",
            "             'gleu.gleu_score': 0.34843304843333334,\n",
            "             'meteor.meteor_score': 0.7349908339666668,\n",
            "             'rouge.rouge_f1_score': 0.5913715913666667,\n",
            "             'rouge.rouge_precision': 0.6666666666666666,\n",
            "             'rouge.rouge_recall': 0.5321428571333334},\n",
            " 'rows': [{'inputs.ground_truth': 'A cat is sitting on the mat.',\n",
            "           'inputs.response': 'The cat sits on the mat.',\n",
            "           'line_number': 0,\n",
            "           'outputs.bleu.bleu_score': 0.37684991640000004,\n",
            "           'outputs.gleu.gleu_score': 0.4230769231,\n",
            "           'outputs.meteor.meteor_score': 0.7454289733,\n",
            "           'outputs.rouge.rouge_f1_score': 0.6153846154,\n",
            "           'outputs.rouge.rouge_precision': 0.6666666667000001,\n",
            "           'outputs.rouge.rouge_recall': 0.5714285714},\n",
            "          {'inputs.ground_truth': 'She loves to read books.',\n",
            "           'inputs.response': 'She enjoys reading books.',\n",
            "           'line_number': 1,\n",
            "           'outputs.bleu.bleu_score': 0.1098261402,\n",
            "           'outputs.gleu.gleu_score': 0.2222222222,\n",
            "           'outputs.meteor.meteor_score': 0.8203389831000001,\n",
            "           'outputs.rouge.rouge_f1_score': 0.4444444444,\n",
            "           'outputs.rouge.rouge_precision': 0.5,\n",
            "           'outputs.rouge.rouge_recall': 0.4},\n",
            "          {'inputs.ground_truth': 'He ran to the store in a hurry.',\n",
            "           'inputs.response': 'He quickly ran to the store.',\n",
            "           'line_number': 2,\n",
            "           'outputs.bleu.bleu_score': 0.34191776500000004,\n",
            "           'outputs.gleu.gleu_score': 0.4,\n",
            "           'outputs.meteor.meteor_score': 0.6392045455,\n",
            "           'outputs.rouge.rouge_f1_score': 0.7142857143,\n",
            "           'outputs.rouge.rouge_precision': 0.8333333333,\n",
            "           'outputs.rouge.rouge_recall': 0.625}],\n",
            " 'studio_url': 'https://ai.azure.com/build/evaluation/b7c2ae61-7de6-4f39-a4e6-5f5541d74be8?wsid=/subscriptions/687537c9-1139-4975-85ff-c4822c224772/resourceGroups/rg-sumohammed-6118_ai/providers/Microsoft.MachineLearningServices/workspaces/sumohammed-0192'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(result)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "aoai_eval",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
